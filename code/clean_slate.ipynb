{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try knn and iterative imputer techniques on limited dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"selected_features_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_label = [\"lab_malaria_any_d0\"]\n",
    "y_label = [\"dxlab_malaria_hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dem_child_house',\n",
       " 'symp_abdopain',\n",
       " 'dem_sex',\n",
       " 'symp_pharyngitis',\n",
       " 'symp_feveronly',\n",
       " 'symp_fever_dur',\n",
       " 'signv_hr1_d0',\n",
       " 'signv_temp_d0',\n",
       " 'date_d30_01',\n",
       " 'sign_skininf',\n",
       " 'signv_muac_d0',\n",
       " 'sign_respdistress',\n",
       " 'symp_loa',\n",
       " 'date_season_meteo',\n",
       " 'days_of_fever',\n",
       " 'dem_age_int',\n",
       " 'symp_diarrhea',\n",
       " 'signv_waz_d0',\n",
       " 'symp_skin_any',\n",
       " 'signv_rr1_d0',\n",
       " 'dem_mat_educat',\n",
       " 'sign_danger',\n",
       " 'symp_vomit',\n",
       " 'symp_cough']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels=list(set(data.columns)-set(y_label))\n",
    "data.dropna(subset=y_label, inplace = True)\n",
    "\n",
    "X = data[X_labels]\n",
    "y = np.array(data[y_label]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_type(data, n_cont_threshold=6):\n",
    "    types = pd.DataFrame([[data.columns[idx], data[val].nunique()] for idx, val in enumerate(data)],\n",
    "                        columns = [\"features\", \"unique_values\"])\n",
    "    numerical = list(types[types[\"unique_values\"]>n_cont_threshold][\"features\"])\n",
    "    categorical = list(types[(types[\"unique_values\"]<n_cont_threshold)&(types[\"unique_values\"]>2)][\"features\"])\n",
    "    binary = list(types[types[\"unique_values\"]==2][\"features\"])\n",
    "    return numerical, categorical, binary\n",
    "\n",
    "\n",
    "numerical, categorical, binary = get_column_type(data[X_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, Binarizer, LabelEncoder, MinMaxScaler\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, SMOTENC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process EXCEPT over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "numX = X[numerical]\n",
    "catX = X[categorical]\n",
    "binX = X[binary]\n",
    "\n",
    "\n",
    "# si = KNNImputer(n_neighbors=3)\n",
    "si = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "for i in categorical:\n",
    "    data[i] = data[i].astype(\"category\")\n",
    "\n",
    "catX_pre = pd.get_dummies(data[categorical])\n",
    "\n",
    "binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "\n",
    "cols=list(numX_pre.columns) +list(catX_pre.columns)+ list(binX_pre.columns)\n",
    "X_pre = pd.DataFrame(np.column_stack((numX_pre, catX_pre, binX_pre)),columns = cols)\n",
    "\n",
    "X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y_pre = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "rus = RandomUnderSampler(sampling_strategy=\"majority\", random_state=0)\n",
    "smote = SMOTE(sampling_strategy = \"minority\", random_state=0)\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "tomek = TomekLinks(sampling_strategy=\"majority\")\n",
    "\n",
    "\n",
    "train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "train_X_oss, train_y_oss = smote.fit_sample(train_X, train_y)\n",
    "train_X_tomek, train_y_tomek = tomek.fit_sample(train_X, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier__max_depth 5\n",
    "# classifier__max_features auto\n",
    "# classifier__min_samples_leaf 4\n",
    "# classifier__n_estimators 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                            min_samples_leaf=3, n_estimators=150).fit(train_X, np.ravel(train_y))\n",
    "rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=150).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "\n",
    "rf_oss = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=150).fit(train_X_oss, np.ravel(train_y_oss))\n",
    "\n",
    "rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                 min_samples_leaf=3, n_estimators=150).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "rf_tomek = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=150).fit(train_X_tomek, np.ravel(train_y_tomek))\n",
    "\n",
    "rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=150).fit(train_X_rus, np.ravel(train_y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier normal\n",
      "acc 0.9323308270676691\n",
      " precision 1.0 \n",
      " recall 0.01818181818181818 \n",
      " rocauc 0.509090909090909\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.8020050125313283\n",
      " precision 0.19883040935672514 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.716897100208002\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier oss\n",
      "acc 0.8508771929824561\n",
      " precision 0.25384615384615383 \n",
      " recall 0.6 \n",
      " rocauc 0.7347240915208614\n",
      "\n",
      "specificity 0.8694481830417228\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8508771929824561\n",
      " precision 0.25384615384615383 \n",
      " recall 0.6 \n",
      " rocauc 0.7347240915208614\n",
      "\n",
      "specificity 0.8694481830417228\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier tomek\n",
      "acc 0.9335839598997494\n",
      " precision 1.0 \n",
      " recall 0.03636363636363636 \n",
      " rocauc 0.5181818181818182\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03636363636363636\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.7055137844611529\n",
      " precision 0.15384615384615385 \n",
      " recall 0.7272727272727273 \n",
      " rocauc 0.7155879114156368\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"normal\", \"ros\", \"oss\",\"smote\",\"tomek\", \"rus\"]\n",
    "for idx, val in enumerate([rf, rf_ros, rf_oss, rf_smote, rf_tomek, rf_rus]):\n",
    "    \n",
    "    preds = val.predict(val_X)\n",
    "    preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "    precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "    recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "    \n",
    "    print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "         accuracy, precision, recall, roc_auc))\n",
    "    \n",
    "    \n",
    "    \n",
    "    tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "    spec = tn/(tn+fp)\n",
    "    sens = tp/(tp+fn)\n",
    "\n",
    "    print(\"specificity {}\\n sensitivity {}\\n\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(val_X)\n",
    "preds_probas = clf.predict_proba(val_X)[:,1]\n",
    "accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "# roc_auc = sklearn.metrics.roc_auc_score(y_pred = preds, y_true = val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_RF = Pipeline(steps = [\n",
    "    (\"classifier\", RandomForestClassifier(random_state=0, bootstrap = True))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parameters_RF= {\n",
    "    \"classifier__n_estimators\":(100, 125, 150, 175, 200),\n",
    "    \"classifier__max_depth\":(4, 5, 6,),\n",
    "    \"classifier__max_features\":(\"auto\",\"sqrt\",\"log2\"),\n",
    "    \"classifier__min_samples_leaf\":(2, 3, 4, 5, 6)\n",
    "#     \"classifier__oob_score\":(False, True)\n",
    "}\n",
    "   \n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909280097511945"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search_cv(pipeline, parameters, X_train, y_train, scoring_method, cv=5, njobs=1, verbose=1):\n",
    "    \n",
    "#     cv = RepeatedStratifiedKFold(n_splits=cvsplits, n_repeats=10, random_state=0)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, return_train_score =True, scoring=scoring_method)\n",
    "    print(\"gridsearch; pipeline: \", [name for name,_ in pipeline.steps])\n",
    "    pprint(parameters)\n",
    "    t0=time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"time: {:.3f}\".format(time()-t0))\n",
    "    print(\"best score: {:.3f}\".format(grid_search.best_score_))\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(param_name, best_parameters[param_name])\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridsearch; pipeline:  ['classifier']\n",
      "{'classifier__max_depth': (3, 5, 7, 9, 11, None),\n",
      " 'classifier__max_features': ('auto', 'sqrt', 'log2', None),\n",
      " 'classifier__min_samples_leaf': (1, 2, 3, 4, 5, 6),\n",
      " 'classifier__n_estimators': (50, 100, 150, 300, 500, 1000)}\n",
      "time: 6755.654\n",
      "best score: 0.768\n",
      "classifier__max_depth 3\n",
      "classifier__max_features auto\n",
      "classifier__min_samples_leaf 5\n",
      "classifier__n_estimators 150\n"
     ]
    }
   ],
   "source": [
    "grid_search_RF = run_grid_search_cv(pipeline_RF, parameters_RF, train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_SVC = Pipeline(steps = [\n",
    "    (\"classifier\", SVC(random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# models = (svm.SVC(kernel='linear', C=C),\n",
    "#           svm.LinearSVC(C=C, max_iter=10000),\n",
    "#           svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "#           svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))\n",
    "parameters_SVC= {\n",
    "    \"classifier__kernel\":(\"linear\",\"rbf\",\"poly\"),\n",
    "    \"classifier__C\":(0.5, 1., 2., 2.5, 3., 3.5, 4., 4.5, 5)\n",
    "#     \"classifier__oob_score\":(False, True)\n",
    "}\n",
    "   \n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridsearch; pipeline:  ['classifier']\n",
      "{'classifier__C': (0.5, 1.0, 2.0, 3.0),\n",
      " 'classifier__kernel': ('linear', 'rbf', 'poly')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.274\n",
      "best score: 0.814\n",
      "classifier__C 2.0\n",
      "classifier__kernel poly\n"
     ]
    }
   ],
   "source": [
    "grid_search_SVC = run_grid_search_cv(pipeline_SVC, parameters_SVC, train_X, train_y, scoring_method= \"precision\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34653465346534656"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(y_pred=preds, y_true=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc\n",
      "acc 0.732\n",
      " precision 0.2445414847161572 \n",
      " recall 0.6666666666666666 \n",
      " rocauc 0.7034534534534534\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(random_state=0, kernel = \"poly\", C = 2.0).fit(train_X_smote, train_y_smote)\n",
    "preds = svc.predict(val_X)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "\n",
    "print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\\n\".format(\"svc\",\n",
    "     accuracy, precision, recall, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid_search_RF_extensive.pkl']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_search_RF, 'grid_search_RF_extensive.pkl', compress = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training size vs performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now let's try with A DIFFERENT way:\n",
    "use all features except lab results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/epoct_ezvir_05dec2018_unlabeled_Jan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_label = [\"lab_malaria_any_d0\"]\n",
    "# y_label = [\"dxlab_malaria_hi\"]\n",
    "y_label = [\"dxlab_malaria_rdt\"]\n",
    "# y_label = [ 'lab_malaria_rdt_d0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_features  = [i for i in data.columns if ((\"malaria\" in i or \"lab\" in i ) and i !=y_label[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels=list(set(data.columns)-set(y_label)-set(lab_features))\n",
    "\n",
    "\n",
    "numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "data.dropna(subset=y_label, inplace = True)\n",
    "X = data[X_labels]\n",
    "y = np.array(data[y_label]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(\"../data/alge_data/epoct_ezvir_05dec2018_dictionary.csv\", encoding = \"unicode-escape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anemia is ok \n",
    "sickle cell (hbss) can really give it away (protected against malaria kinda) NO\n",
    "hiv is ok but increases risk of transmission\n",
    "any malaria : not ok NO\n",
    "typhoid is ok \n",
    "uti ok probably\n",
    "bcx probably ok\n",
    "crp probably too useful NO\n",
    "hb ? i mean maybe but is correlated NO\n",
    "hrp 2 NO\n",
    "lactate probablynot NO\n",
    "pct NO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "numX = X[numerical]\n",
    "catX = X[categorical]\n",
    "binX = X[binary]\n",
    "\n",
    "\n",
    "si = SimpleImputer(strategy=\"median\")\n",
    "mms = MinMaxScaler()\n",
    "ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "for i in categorical:\n",
    "    data[i] = data[i].astype(\"category\")\n",
    "\n",
    "catX_pre = pd.get_dummies(data[categorical])\n",
    "\n",
    "binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "\n",
    "cols=list(numX_pre.columns) +list(catX_pre.columns)+ list(binX_pre.columns)\n",
    "X_pre = pd.DataFrame(np.column_stack((numX_pre, catX_pre, binX_pre)),columns = cols)\n",
    "\n",
    "X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y_pre = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# best score: 0.764\n",
    "# classifier__max_depth 5\n",
    "# classifier__max_features auto\n",
    "# classifier__min_samples_leaf 3\n",
    "# classifier__n_estimators 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                            min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                               min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                 min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi_000\\Anaconda3\\envs\\clinicolab\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier normal\n",
      "acc 0.9201065246338216\n",
      " precision 0.0 \n",
      " recall 0.0 \n",
      " rocauc 0.5\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.8042609853528628\n",
      " precision 0.24260355029585798 \n",
      " recall 0.6833333333333333 \n",
      " rocauc 0.7490472744814278\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.7177097203728362\n",
      " precision 0.18333333333333332 \n",
      " recall 0.7333333333333333 \n",
      " rocauc 0.7248432223830198\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8628495339547271\n",
      " precision 0.3063063063063063 \n",
      " recall 0.5666666666666667 \n",
      " rocauc 0.7276169802219007\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "    \n",
    "    preds = val.predict(val_X)\n",
    "    preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "    precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "    recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "    \n",
    "    print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "         accuracy, precision, recall, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "clf.fit(train_X, train_y)\n",
    "preds = clf.predict(val_X)\n",
    "preds_probas = clf.predict_proba(val_X)[:,1]\n",
    "accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "# roc_auc = sklearn.metrics.roc_auc_score(y_pred = preds, y_true = val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.4583333333333333\n",
      " recall 0.2619047619047619\n",
      " accuracy 0.8826666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"precision {}\\n recall {}\\n accuracy {}\".format(precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sign_wheeze', 'sign_eczema', 'symp_sev_cns', 'signv_waz_d0',\n",
       "       'signv_rr1_d0', 'sign_tinea', 'sign_danger_d1', 'symp_liquidstool',\n",
       "       'hist_ttt_before', 'symp_diarrhea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[np.argpartition(rf.feature_importances_, -10)[-10:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridsearch; pipeline:  ['classifier']\n",
      "{'classifier__max_depth': (5, 10, None),\n",
      " 'classifier__max_features': ('auto', 'sqrt', 'log2', None),\n",
      " 'classifier__min_samples_leaf': (1, 2, 3, 4),\n",
      " 'classifier__n_estimators': (100, 300, 500)}\n",
      "time: 1236.559\n",
      "best score: 0.764\n",
      "classifier__max_depth 5\n",
      "classifier__max_features auto\n",
      "classifier__min_samples_leaf 3\n",
      "classifier__n_estimators 500\n"
     ]
    }
   ],
   "source": [
    "grid_search_RF = run_grid_search_cv(pipeline_RF, parameters_RF, train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now let's try with A NEW DIFFERENT : try different labels\n",
    "use unrestricted set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$(jupyter',\n",
       " '.ipynb_checkpoints',\n",
       " 'clean_slate.ipynb',\n",
       " 'figures',\n",
       " 'grid_search_ABC.pkl',\n",
       " 'grid_search_BNB.pkl',\n",
       " 'grid_search_LR.pkl',\n",
       " 'grid_search_NN.pkl',\n",
       " 'grid_search_RF.pkl',\n",
       " 'grid_search_RF_extensive.pkl',\n",
       " 'interpretability_shap_intro_python.ipynb',\n",
       " 'ml_explanations.ipynb',\n",
       " 'ml_explanations_READY-Copy1.ipynb',\n",
       " 'ml_explanations_READY-Copy2.ipynb',\n",
       " 'ml_explanations_READY.ipynb',\n",
       " 'ml_explanations_SAVINGGRACE.ipynb',\n",
       " 'model_comparison.ipynb',\n",
       " 'model_comparison_final.ipynb',\n",
       " 'model_comparison_intro.ipynb',\n",
       " 'model_helpers.ipynb',\n",
       " 'model_helpers.py',\n",
       " 'preprocessing.ipynb',\n",
       " 'selected_features_all_labels_data',\n",
       " 'selected_features_data',\n",
       " 'Thumbs.db',\n",
       " 'utils.ipynb',\n",
       " 'utils_2.ipynb']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3192, 32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp=data.dropna(subset=[\"lab_malaria_any_d0\"])\n",
    "temp.iloc[np.where(temp[\"lab_malaria_any_d0\"]!=temp[\"lab_malaria_any_d0.1\"])[0]][[\"lab_malaria_any_d0\",\"lab_malaria_any_d0.1\"]]\n",
    "so just drop the .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"selected_features_all_labels_data\")\n",
    "insufficient = [\"dxlab_malaria_hist\", \"dxlab_malaria_low\", \"dxlab_malaria_mod\",\"lab_malaria_rdt_d0\",\"lab_malaria_rdtbad_d3\"]\n",
    "y_labels  = [i for i in data.columns if \"malaria\" in i and i not in insufficient]\n",
    "y_labels\n",
    "lab_features  = [i for i in data.columns if ((\"malaria\" in i or \"lab\" in i ) and i not in y_labels)]\n",
    "data.drop(lab_features, inplace=True, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hist no low no rdtbad no : too few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [data[i].value_counts() for i in y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab_malaria_any_d0',\n",
       " 'dxlab_malaria_hi',\n",
       " 'dxlab_malaria_hsrdt',\n",
       " 'dxlab_malaria_rdt',\n",
       " 'dxlab_malaria_vlow',\n",
       " 'lab_malaria_any_d0.1',\n",
       " 'lab_malaria_hsrdt_d0',\n",
       " 'lab_malaria_rdtbad_d0']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "${\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} }{\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specificity, selectivity or true negative rate (TNR)\n",
    "$\n",
    "{\\displaystyle \\mathrm {TNR} ={\\frac {\\mathrm {TN} }{\\mathrm {N} }}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}=1-\\mathrm {FPR} }{\\displaystyle \\mathrm {TNR} ={\\frac {\\mathrm {TN} }{\\mathrm {N} }}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}=1-\\mathrm {FPR} }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " lab_malaria_any_d0 \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7813333333333333\n",
      " precision 0.2727272727272727 \n",
      " recall 0.5714285714285714 \n",
      " rocauc 0.6896181896181895\n",
      "\n",
      "\n",
      "specificity 0.8078078078078078\n",
      " sensitivity 0.5714285714285714\n",
      "\n",
      "\n",
      " dxlab_malaria_hi \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8558897243107769\n",
      " precision 0.265625 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.745833843142053\n",
      "\n",
      "\n",
      "specificity 0.873485868102288\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      " dxlab_malaria_hsrdt \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8468708388814914\n",
      " precision 0.288 \n",
      " recall 0.5806451612903226 \n",
      " rocauc 0.725736223605974\n",
      "\n",
      "\n",
      "specificity 0.8708272859216255\n",
      " sensitivity 0.5806451612903226\n",
      "\n",
      "\n",
      " dxlab_malaria_rdt \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8428761651131824\n",
      " precision 0.2661290322580645 \n",
      " recall 0.55 \n",
      " rocauc 0.7091534008683068\n",
      "\n",
      "\n",
      "specificity 0.8683068017366136\n",
      " sensitivity 0.55\n",
      "\n",
      "\n",
      " dxlab_malaria_vlow \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7907268170426065\n",
      " precision 0.03205128205128205 \n",
      " recall 0.23809523809523808 \n",
      " rocauc 0.5218790218790219\n",
      "\n",
      "\n",
      "specificity 0.8056628056628057\n",
      " sensitivity 0.23809523809523808\n",
      "\n",
      "\n",
      " lab_malaria_any_d0.1 \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7773333333333333\n",
      " precision 0.27807486631016043 \n",
      " recall 0.6190476190476191 \n",
      " rocauc 0.7081724581724582\n",
      "\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.6190476190476191\n",
      "\n",
      "\n",
      " lab_malaria_hsrdt_d0 \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8468708388814914\n",
      " precision 0.288 \n",
      " recall 0.5806451612903226 \n",
      " rocauc 0.725736223605974\n",
      "\n",
      "\n",
      "specificity 0.8708272859216255\n",
      " sensitivity 0.5806451612903226\n",
      "\n",
      "\n",
      " lab_malaria_rdtbad_d0 \n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7336683417085427\n",
      " precision 0.2169811320754717 \n",
      " recall 0.5 \n",
      " rocauc 0.6321022727272727\n",
      "\n",
      "\n",
      "specificity 0.7642045454545454\n",
      " sensitivity 0.5\n"
     ]
    }
   ],
   "source": [
    "for y_label in y_labels:\n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = SimpleImputer(strategy=\"median\")\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "\n",
    "#     names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "    names = [\"smote\"]\n",
    "    print(\"\\n\\n\",y_label,\"\\n\")\n",
    "\n",
    "#     for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "    for idx, val in enumerate([ rf_smote]):\n",
    "\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "        print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "             accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now let's try with A NEW DIFFERENT way:\n",
    "\n",
    "no median filling\n",
    "\n",
    "use all features\n",
    "\n",
    "predict dxlab_malaria_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " median \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.9323308270676691\n",
      " precision 1.0 \n",
      " recall 0.01818181818181818 \n",
      " rocauc 0.509090909090909\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.8020050125313283\n",
      " precision 0.1952662721893491 \n",
      " recall 0.6 \n",
      " rocauc 0.7084791386271871\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.7042606516290727\n",
      " precision 0.15057915057915058 \n",
      " recall 0.7090909090909091 \n",
      " rocauc 0.7064970023247277\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8558897243107769\n",
      " precision 0.265625 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.745833843142053\n",
      "\n",
      "specificity 0.873485868102288\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " mean \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.9323308270676691\n",
      " precision 1.0 \n",
      " recall 0.01818181818181818 \n",
      " rocauc 0.509090909090909\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.8045112781954887\n",
      " precision 0.20118343195266272 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.7182429952281904\n",
      "\n",
      "specificity 0.8183041722745625\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.7055137844611529\n",
      " precision 0.15384615384615385 \n",
      " recall 0.7272727272727273 \n",
      " rocauc 0.7155879114156368\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8458646616541353\n",
      " precision 0.25 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.7404502630612995\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " most_frequent \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.9323308270676691\n",
      " precision 1.0 \n",
      " recall 0.01818181818181818 \n",
      " rocauc 0.509090909090909\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.8020050125313283\n",
      " precision 0.1952662721893491 \n",
      " recall 0.6 \n",
      " rocauc 0.7084791386271871\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.7092731829573935\n",
      " precision 0.15294117647058825 \n",
      " recall 0.7090909090909091 \n",
      " rocauc 0.7091887923651047\n",
      "\n",
      "specificity 0.7092866756393001\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.8659147869674185\n",
      " precision 0.2833333333333333 \n",
      " recall 0.6181818181818182 \n",
      " rocauc 0.7512174232228068\n",
      "\n",
      "specificity 0.8842530282637954\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label = \"dxlab_malaria_hi\"\n",
    "\n",
    "for scorer in [\"median\", \"mean\",\"most_frequent\"]:\n",
    "    \n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = SimpleImputer(strategy=scorer)\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "\n",
    "    names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "#     names = [\"smote\"]\n",
    "    print(\"\\n\\n\",scorer,\"\\n\")\n",
    "\n",
    "    for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "#     for idx, val in enumerate([ rf_smote]):\n",
    "\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "        print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "             accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now try smart imputation\n",
    "\n",
    "using lab malaria any d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " number of neighbors  1 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7186666666666667\n",
      " precision 0.24081632653061225 \n",
      " recall 0.7023809523809523 \n",
      " rocauc 0.7115508365508364\n",
      "\n",
      "specificity 0.7207207207207207\n",
      " sensitivity 0.7023809523809523\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.668\n",
      " precision 0.21649484536082475 \n",
      " recall 0.75 \n",
      " rocauc 0.7038288288288288\n",
      "\n",
      "specificity 0.6576576576576577\n",
      " sensitivity 0.75\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.772\n",
      " precision 0.27225130890052357 \n",
      " recall 0.6190476190476191 \n",
      " rocauc 0.7051694551694552\n",
      "\n",
      "specificity 0.7912912912912913\n",
      " sensitivity 0.6190476190476191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  2 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7173333333333334\n",
      " precision 0.24193548387096775 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.716001716001716\n",
      "\n",
      "specificity 0.7177177177177178\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6666666666666666\n",
      " precision 0.21379310344827587 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6978764478764479\n",
      "\n",
      "specificity 0.6576576576576577\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7746666666666666\n",
      " precision 0.2727272727272727 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7014693264693265\n",
      "\n",
      "specificity 0.7957957957957958\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  3 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7173333333333334\n",
      " precision 0.24193548387096775 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.716001716001716\n",
      "\n",
      "specificity 0.7177177177177178\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6573333333333333\n",
      " precision 0.20875420875420875 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6926211926211926\n",
      "\n",
      "specificity 0.6471471471471472\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7706666666666667\n",
      " precision 0.26344086021505375 \n",
      " recall 0.5833333333333334 \n",
      " rocauc 0.6888138138138139\n",
      "\n",
      "specificity 0.7942942942942943\n",
      " sensitivity 0.5833333333333334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  4 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7133333333333334\n",
      " precision 0.23904382470119523 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7137494637494638\n",
      "\n",
      "specificity 0.7132132132132132\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6653333333333333\n",
      " precision 0.21305841924398625 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6971256971256972\n",
      "\n",
      "specificity 0.6561561561561562\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7706666666666667\n",
      " precision 0.26842105263157895 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.6992170742170741\n",
      "\n",
      "specificity 0.7912912912912913\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  5 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7093333333333334\n",
      " precision 0.23622047244094488 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7114972114972116\n",
      "\n",
      "specificity 0.7087087087087087\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.66\n",
      " precision 0.20819112627986347 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.688921063921064\n",
      "\n",
      "specificity 0.6516516516516516\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7773333333333333\n",
      " precision 0.27807486631016043 \n",
      " recall 0.6190476190476191 \n",
      " rocauc 0.7081724581724582\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.6190476190476191\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  6 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7186666666666667\n",
      " precision 0.242914979757085 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7167524667524668\n",
      "\n",
      "specificity 0.7192192192192193\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6653333333333333\n",
      " precision 0.21107266435986158 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.6919240669240669\n",
      "\n",
      "specificity 0.6576576576576577\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7706666666666667\n",
      " precision 0.26842105263157895 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.6992170742170741\n",
      "\n",
      "specificity 0.7912912912912913\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  7 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7186666666666667\n",
      " precision 0.242914979757085 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7167524667524668\n",
      "\n",
      "specificity 0.7192192192192193\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6666666666666666\n",
      " precision 0.21180555555555555 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.6926748176748178\n",
      "\n",
      "specificity 0.6591591591591591\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7746666666666666\n",
      " precision 0.2677595628415301 \n",
      " recall 0.5833333333333334 \n",
      " rocauc 0.6910660660660661\n",
      "\n",
      "specificity 0.7987987987987988\n",
      " sensitivity 0.5833333333333334\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  8 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7173333333333334\n",
      " precision 0.24193548387096775 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.716001716001716\n",
      "\n",
      "specificity 0.7177177177177178\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6613333333333333\n",
      " precision 0.2108843537414966 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6948734448734449\n",
      "\n",
      "specificity 0.6516516516516516\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.776\n",
      " precision 0.27419354838709675 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7022200772200773\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  9 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7173333333333334\n",
      " precision 0.24193548387096775 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.716001716001716\n",
      "\n",
      "specificity 0.7177177177177178\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6613333333333333\n",
      " precision 0.2108843537414966 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6948734448734449\n",
      "\n",
      "specificity 0.6516516516516516\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7773333333333333\n",
      " precision 0.2756756756756757 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.702970827970828\n",
      "\n",
      "specificity 0.7987987987987988\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  10 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.716\n",
      " precision 0.24096385542168675 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7152509652509653\n",
      "\n",
      "specificity 0.7162162162162162\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6666666666666666\n",
      " precision 0.21379310344827587 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6978764478764479\n",
      "\n",
      "specificity 0.6576576576576577\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.776\n",
      " precision 0.27419354838709675 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7022200772200773\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  11 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7146666666666667\n",
      " precision 0.24 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7145002145002146\n",
      "\n",
      "specificity 0.7147147147147147\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier rus\n",
      "acc 0.6653333333333333\n",
      " precision 0.2150170648464164 \n",
      " recall 0.75 \n",
      " rocauc 0.7023273273273274\n",
      "\n",
      "specificity 0.6546546546546547\n",
      " sensitivity 0.75\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7786666666666666\n",
      " precision 0.28191489361702127 \n",
      " recall 0.6309523809523809 \n",
      " rocauc 0.7141248391248392\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.6309523809523809\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  12 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.712\n",
      " precision 0.23809523809523808 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7129987129987131\n",
      "\n",
      "specificity 0.7117117117117117\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6666666666666666\n",
      " precision 0.21379310344827587 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6978764478764479\n",
      "\n",
      "specificity 0.6576576576576577\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7733333333333333\n",
      " precision 0.26881720430107525 \n",
      " recall 0.5952380952380952 \n",
      " rocauc 0.6955169455169455\n",
      "\n",
      "specificity 0.7957957957957958\n",
      " sensitivity 0.5952380952380952\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  13 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7106666666666667\n",
      " precision 0.23715415019762845 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7122479622479623\n",
      "\n",
      "specificity 0.7102102102102102\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.664\n",
      " precision 0.2103448275862069 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.6911733161733162\n",
      "\n",
      "specificity 0.6561561561561562\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7733333333333333\n",
      " precision 0.2712765957446808 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7007185757185758\n",
      "\n",
      "specificity 0.7942942942942943\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  14 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.716\n",
      " precision 0.24096385542168675 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7152509652509653\n",
      "\n",
      "specificity 0.7162162162162162\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6613333333333333\n",
      " precision 0.2108843537414966 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6948734448734449\n",
      "\n",
      "specificity 0.6516516516516516\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7733333333333333\n",
      " precision 0.2712765957446808 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7007185757185758\n",
      "\n",
      "specificity 0.7942942942942943\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  15 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7133333333333334\n",
      " precision 0.23904382470119523 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7137494637494638\n",
      "\n",
      "specificity 0.7132132132132132\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.66\n",
      " precision 0.20819112627986347 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.688921063921064\n",
      "\n",
      "specificity 0.6516516516516516\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7773333333333333\n",
      " precision 0.273224043715847 \n",
      " recall 0.5952380952380952 \n",
      " rocauc 0.6977691977691978\n",
      "\n",
      "specificity 0.8003003003003003\n",
      " sensitivity 0.5952380952380952\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  16 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.712\n",
      " precision 0.23809523809523808 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7129987129987131\n",
      "\n",
      "specificity 0.7117117117117117\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6586666666666666\n",
      " precision 0.21140939597315436 \n",
      " recall 0.75 \n",
      " rocauc 0.6985735735735736\n",
      "\n",
      "specificity 0.6471471471471472\n",
      " sensitivity 0.75\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7746666666666666\n",
      " precision 0.2702702702702703 \n",
      " recall 0.5952380952380952 \n",
      " rocauc 0.6962676962676962\n",
      "\n",
      "specificity 0.7972972972972973\n",
      " sensitivity 0.5952380952380952\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  17 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.712\n",
      " precision 0.23809523809523808 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7129987129987131\n",
      "\n",
      "specificity 0.7117117117117117\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6586666666666666\n",
      " precision 0.21140939597315436 \n",
      " recall 0.75 \n",
      " rocauc 0.6985735735735736\n",
      "\n",
      "specificity 0.6471471471471472\n",
      " sensitivity 0.75\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7733333333333333\n",
      " precision 0.26881720430107525 \n",
      " recall 0.5952380952380952 \n",
      " rocauc 0.6955169455169455\n",
      "\n",
      "specificity 0.7957957957957958\n",
      " sensitivity 0.5952380952380952\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  18 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.712\n",
      " precision 0.23809523809523808 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7129987129987131\n",
      "\n",
      "specificity 0.7117117117117117\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6626666666666666\n",
      " precision 0.20962199312714777 \n",
      " recall 0.7261904761904762 \n",
      " rocauc 0.6904225654225655\n",
      "\n",
      "specificity 0.6546546546546547\n",
      " sensitivity 0.7261904761904762\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7786666666666666\n",
      " precision 0.27717391304347827 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7037215787215787\n",
      "\n",
      "specificity 0.8003003003003003\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  19 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.712\n",
      " precision 0.23809523809523808 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7129987129987131\n",
      "\n",
      "specificity 0.7117117117117117\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.66\n",
      " precision 0.21016949152542372 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6941226941226941\n",
      "\n",
      "specificity 0.6501501501501501\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.78\n",
      " precision 0.2786885245901639 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7044723294723295\n",
      "\n",
      "specificity 0.8018018018018018\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  20 \n",
      "\n",
      "RandomForestClassifier normal\n",
      "acc 0.892\n",
      " precision 1.0 \n",
      " recall 0.03571428571428571 \n",
      " rocauc 0.5178571428571429\n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03571428571428571\n",
      "\n",
      "\n",
      "RandomForestClassifier ros\n",
      "acc 0.7133333333333334\n",
      " precision 0.23904382470119523 \n",
      " recall 0.7142857142857143 \n",
      " rocauc 0.7137494637494638\n",
      "\n",
      "specificity 0.7132132132132132\n",
      " sensitivity 0.7142857142857143\n",
      "\n",
      "\n",
      "RandomForestClassifier rus\n",
      "acc 0.6653333333333333\n",
      " precision 0.21305841924398625 \n",
      " recall 0.7380952380952381 \n",
      " rocauc 0.6971256971256972\n",
      "\n",
      "specificity 0.6561561561561562\n",
      " sensitivity 0.7380952380952381\n",
      "\n",
      "\n",
      "RandomForestClassifier smote\n",
      "acc 0.7786666666666666\n",
      " precision 0.27717391304347827 \n",
      " recall 0.6071428571428571 \n",
      " rocauc 0.7037215787215787\n",
      "\n",
      "specificity 0.8003003003003003\n",
      " sensitivity 0.6071428571428571\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label = \"lab_malaria_any_d0\"\n",
    "\n",
    "for nn in np.linspace(1,20,20,dtype=\"int\"):\n",
    "    \n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = KNNImputer(n_neighbors=nn)\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "\n",
    "    names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "#     names = [\"smote\"]\n",
    "    print(\"\\n\\n number of neighbors \",nn,\"\\n\")\n",
    "\n",
    "    for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "#     for idx, val in enumerate([ rf_smote]):\n",
    "\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "        print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "             accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so 0.7 and 0.7 can be done which is meh but well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now same thing but with malaria)hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " number of neighbors  1 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.6998654104979811\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8707940780619112\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  2 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8761776581426649\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  3 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8115746971736204\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6971736204576043\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8721399730820996\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  4 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7065948855989233\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8694481830417228\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  5 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  6 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.702557200538358\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  7 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6958277254374159\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  8 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6971736204576043\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  9 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6971736204576043\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8707940780619112\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  10 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  11 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  12 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8183041722745625\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  13 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6944818304172274\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8694481830417228\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  14 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6971736204576043\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8640646029609691\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  15 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6998654104979811\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8694481830417228\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  16 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8707940780619112\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  17 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7052489905787349\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  18 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  19 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  20 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6944818304172274\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label = \"dxlab_malaria_hi\"\n",
    "\n",
    "for nn in np.linspace(1,20,20,dtype=\"int\"):\n",
    "    \n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = KNNImputer(n_neighbors=nn)\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "\n",
    "    names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "#     names = [\"smote\"]\n",
    "    print(\"\\n\\n number of neighbors \",nn,\"\\n\")\n",
    "\n",
    "    for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "#     for idx, val in enumerate([ rf_smote]):\n",
    "\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "#         print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "#              accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same thing but with more nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " number of neighbors  1 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.6998654104979811\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8707940780619112\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  11 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  21 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.6944818304172274\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8681022880215343\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  32 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.5818181818181818\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  42 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  53 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8169582772543742\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  63 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8640646029609691\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  74 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "specificity 0.6958277254374159\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  84 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  95 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8613728129205922\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  105 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8156123822341858\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "specificity 0.6985195154777928\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  116 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8667563930013459\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  126 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.702557200538358\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8640646029609691\n",
      " sensitivity 0.6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  137 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  147 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8640646029609691\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  158 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.702557200538358\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  168 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7272727272727273\n",
      "\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  179 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7012113055181696\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8613728129205922\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  189 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.7039030955585465\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8627187079407806\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " number of neighbors  200 \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "specificity 0.702557200538358\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "specificity 0.8613728129205922\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label = \"dxlab_malaria_hi\"\n",
    "\n",
    "for nn in np.linspace(1,200,20, dtype=\"int\"):\n",
    "    \n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = KNNImputer(n_neighbors=nn)\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "\n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "\n",
    "\n",
    "    names = [\"normal\", \"ros\", \"rus\", \"smote\"]\n",
    "#     names = [\"smote\"]\n",
    "    print(\"\\n\\n number of neighbors \",nn,\"\\n\")\n",
    "\n",
    "    for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote]):\n",
    "#     for idx, val in enumerate([ rf_smote]):\n",
    "\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "#         print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "#              accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and now try with iterative imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " strat for Iterative imputing  median \n",
      "\n",
      "normal \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "ros \n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "rus \n",
      "\n",
      "specificity 0.7065948855989233\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "smote \n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "oss \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03636363636363636\n",
      "\n",
      "\n",
      "tomek \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.05454545454545454\n",
      "\n",
      "\n",
      "smotetomek \n",
      "\n",
      "specificity 0.8600269179004038\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " strat for Iterative imputing  mean \n",
      "\n",
      "normal \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "ros \n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "rus \n",
      "\n",
      "specificity 0.7065948855989233\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "smote \n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "oss \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03636363636363636\n",
      "\n",
      "\n",
      "tomek \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.05454545454545454\n",
      "\n",
      "\n",
      "smotetomek \n",
      "\n",
      "specificity 0.8681022880215343\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " strat for Iterative imputing  most_frequent \n",
      "\n",
      "normal \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.01818181818181818\n",
      "\n",
      "\n",
      "ros \n",
      "\n",
      "specificity 0.8142664872139973\n",
      " sensitivity 0.6363636363636364\n",
      "\n",
      "\n",
      "rus \n",
      "\n",
      "specificity 0.7065948855989233\n",
      " sensitivity 0.7090909090909091\n",
      "\n",
      "\n",
      "smote \n",
      "\n",
      "specificity 0.8654104979811574\n",
      " sensitivity 0.6181818181818182\n",
      "\n",
      "\n",
      "oss \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.03636363636363636\n",
      "\n",
      "\n",
      "tomek \n",
      "\n",
      "specificity 1.0\n",
      " sensitivity 0.05454545454545454\n",
      "\n",
      "\n",
      "smotetomek \n",
      "\n",
      "specificity 0.8640646029609691\n",
      " sensitivity 0.6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_label = \"dxlab_malaria_hi\"\n",
    "\n",
    "for strat in [\"median\", \"mean\", \"most_frequent\"]:\n",
    "    \n",
    "    X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "    numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "    temp   = data.dropna(subset=[y_label])\n",
    "    \n",
    "    X = temp[X_labels]\n",
    "    y = np.array(temp[y_label]).ravel()\n",
    "    \n",
    "    numX = X[numerical]\n",
    "    catX = X[categorical]\n",
    "    binX = X[binary]\n",
    "\n",
    "\n",
    "    si = IterativeImputer(initial_strategy=strat)\n",
    "    mms = MinMaxScaler()\n",
    "    ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "    numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "    for i in categorical:\n",
    "        data[i] = data[i].astype(\"category\")\n",
    "\n",
    "    catX_temp = pd.get_dummies(temp[categorical])\n",
    "    catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "    binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "    numX_pre.reset_index(drop=True, inplace=True)\n",
    "    catX_pre.reset_index(drop=True, inplace=True)\n",
    "    binX_pre.reset_index(drop=True, inplace=True)\n",
    "    X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "   \n",
    "    X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "    le=LabelEncoder()\n",
    "\n",
    "    y_pre = le.fit_transform(y)\n",
    "\n",
    "    train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "    smote = SMOTE(sampling_strategy = \"auto\", random_state=0)\n",
    "    oss = OneSidedSelection(random_state=0)\n",
    "    tomek = TomekLinks(sampling_strategy=\"auto\")\n",
    "    smotetomek = SMOTETomek(sampling_strategy=\"auto\")\n",
    "    \n",
    "    \n",
    "    train_X_ros, train_y_ros = ros.fit_sample(train_X, train_y)\n",
    "    train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "    train_X_smote, train_y_smote = smote.fit_sample(train_X, train_y)\n",
    "    train_X_oss, train_y_oss = oss.fit_sample(train_X, train_y)\n",
    "    train_X_tomek, train_y_tomek = tomek.fit_sample(train_X, train_y)\n",
    "    train_X_smotetomek, train_y_smotetomek = smotetomek.fit_sample(train_X, train_y)\n",
    "\n",
    "\n",
    "    rf  = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                min_samples_leaf=3, n_estimators=200).fit(train_X, np.ravel(train_y))\n",
    "    rf_ros = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_ros, np.ravel(train_y_ros))\n",
    "    rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                   min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "    rf_smote = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                     min_samples_leaf=3, n_estimators=200).fit(train_X_smote, np.ravel(train_y_smote))\n",
    "\n",
    "    rf_oss = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                         min_samples_leaf=3, n_estimators=200).fit(train_X_oss, np.ravel(train_y_oss))\n",
    "    rf_tomek = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                         min_samples_leaf=3, n_estimators=200).fit(train_X_tomek, np.ravel(train_y_tomek))\n",
    "    rf_smotetomek = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "                                         min_samples_leaf=3, n_estimators=200).fit(train_X_smotetomek, np.ravel(train_y_smotetomek))\n",
    "\n",
    "    names = [\"normal\", \"ros\", \"rus\", \"smote\",\"oss\",\"tomek\",\"smotetomek\"]\n",
    "#     names = [\"smote\"]\n",
    "    print(\"\\n\\n strat for Iterative imputing \",strat,\"\\n\")\n",
    "\n",
    "    for idx, val in enumerate([rf, rf_ros, rf_rus, rf_smote, rf_oss, rf_tomek, rf_smotetomek]):\n",
    "#     for idx, val in enumerate([ rf_smote]):\n",
    "        print(names[idx],\"\\n\")\n",
    "        preds = val.predict(val_X)\n",
    "        preds_probas = val.predict_proba(val_X)[:,1]\n",
    "\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "        precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "        recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "        roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "#         print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    "#              accuracy, precision, recall, roc_auc))\n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "        spec = tn/(tn+fp)\n",
    "        sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "        print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUS does well, especially to max sens\n",
    "\n",
    "ROS and SMOTE do well overall but yield lower sens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will now CV\n",
    "\n",
    "- use RUS\n",
    "- use knn imputer with n = 10, or use mean imputer\n",
    "- cv on rf parameters for now\n",
    "- score function should be sens!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"selected_features_all_labels_data\")\n",
    "insufficient = [\"dxlab_malaria_hist\", \"dxlab_malaria_low\", \"dxlab_malaria_mod\",\"lab_malaria_rdt_d0\",\"lab_malaria_rdtbad_d3\"]\n",
    "y_labels  = [i for i in data.columns if \"malaria\" in i and i not in insufficient]\n",
    "lab_features  = [i for i in data.columns if ((\"malaria\" in i or \"lab\" in i ) and i not in y_labels)]\n",
    "data.drop(lab_features, inplace=True, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = \"dxlab_malaria_hi\"\n",
    "\n",
    "X_labels=list(set(data.columns)-set(y_labels))\n",
    "\n",
    "numerical, categorical, binary = get_column_type(data[X_labels])\n",
    "\n",
    "temp   = data.dropna(subset=[y_label])\n",
    "\n",
    "X = temp[X_labels]\n",
    "y = np.array(temp[y_label]).ravel()\n",
    "\n",
    "numX = X[numerical]\n",
    "catX = X[categorical]\n",
    "binX = X[binary]\n",
    "\n",
    "\n",
    "si = KNNImputer(n_neighbors = 9)\n",
    "mms = MinMaxScaler()\n",
    "ohe=OneHotEncoder(categories=\"auto\",handle_unknown=\"ignore\")\n",
    "\n",
    "numX_pre = pd.DataFrame(mms.fit_transform(si.fit_transform(numX)), columns=numerical)\n",
    "\n",
    "\n",
    "for i in categorical:\n",
    "    data[i] = data[i].astype(\"category\")\n",
    "\n",
    "catX_temp = pd.get_dummies(temp[categorical])\n",
    "catX_pre = pd.DataFrame(si.fit_transform(catX_temp), columns = catX_temp.columns)\n",
    "binX_pre = pd.DataFrame(si.fit_transform(binX), columns=binary)\n",
    "\n",
    "numX_pre.reset_index(drop=True, inplace=True)\n",
    "catX_pre.reset_index(drop=True, inplace=True)\n",
    "binX_pre.reset_index(drop=True, inplace=True)\n",
    "X_pre = pd.concat([numX_pre, catX_pre, binX_pre], axis=1)\n",
    "\n",
    "X_pre_labels=list(set(X_pre.columns))\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y_pre = le.fit_transform(y)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_pre, y_pre, random_state=0)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=\"auto\", random_state=0)\n",
    "\n",
    "train_X_rus, train_y_rus = rus.fit_sample(train_X, train_y)\n",
    "\n",
    "# rf_rus = RandomForestClassifier(random_state=0, max_depth=5, max_features=\"auto\", \n",
    "#                                    min_samples_leaf=3, n_estimators=200).fit(train_X_rus, np.ravel(train_y_rus))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import auc, make_scorer\n",
    "\n",
    "# def score_sensitivity(y_true, y_pred):\n",
    "#     tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=y_true, y_pred=y_pred).ravel()\n",
    "#     spec = tn/(tn+fp)\n",
    "    \n",
    "#     if tp+fn!= 0:\n",
    "#         sens = tp/(tp+fn)\n",
    "#     else:\n",
    "#         sens=0\n",
    "#     return sens\n",
    "\n",
    "\n",
    "\n",
    "# def score_specificity(y_true, y_pred):\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    \n",
    "#     return tpr\n",
    "\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import make_scorer\n",
    "# scorer = make_scorer(score_sensitivity, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search_cv(pipeline, parameters, X_train, y_train, scoring_method, cv=5, njobs=1, verbose=1):\n",
    "    \n",
    "#     cv = RepeatedStratifiedKFold(n_splits=cvsplits, n_repeats=10, random_state=0)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, return_train_score =True, scoring=scoring_method)\n",
    "    print(\"gridsearch; pipeline: \", [name for name,_ in pipeline.steps])\n",
    "    pprint(parameters)\n",
    "    t0=time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"time: {:.3f}\".format(time()-t0))\n",
    "    print(\"best score: {:.3f}\".format(grid_search.best_score_))\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(param_name, best_parameters[param_name])\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_RF = Pipeline(steps = [\n",
    "    (\"classifier\", RandomForestClassifier(random_state=0, bootstrap = True))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parameters_RF= {\n",
    "    \"classifier__n_estimators\":(100, 125, 150, 175, ),\n",
    "    \"classifier__max_depth\":(3, 4, 5,),\n",
    "    \n",
    "    \"classifier__min_samples_leaf\":(5, 6, 7, 8, 9, 10)\n",
    "}\n",
    "#    Cohen’s kappa: a statistic that measures inter-annotator agreement.\n",
    "\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridsearch; pipeline:  ['classifier']\n",
      "{'classifier__max_depth': (3, 4, 5),\n",
      " 'classifier__min_samples_leaf': (5, 6, 7, 8, 9, 10),\n",
      " 'classifier__n_estimators': (100, 125, 150, 175)}\n",
      "time: 73.839\n",
      "best score: 0.802\n",
      "classifier__max_depth 4\n",
      "classifier__min_samples_leaf 5\n",
      "classifier__n_estimators 100\n"
     ]
    }
   ],
   "source": [
    "grid_search_RF_sens = run_grid_search_cv(pipeline_RF, parameters_RF, \n",
    "                                         train_X_rus, train_y_rus, scoring_method =\"recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=RandomForestClassifier(random_state=0, \n",
    "                            bootstrap=True, \n",
    "                            n_estimators=100, \n",
    "                            min_samples_leaf=5, \n",
    "                            max_features=\"auto\"\n",
    "                            ,\n",
    "                            max_depth=4).fit(train_X_rus, train_y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier rus\n",
      "acc 0.5150375939849624\n",
      " precision 0.10476190476190476 \n",
      " recall 0.8 \n",
      " rocauc 0.646971736204576\n",
      "\n",
      "specificity 0.4939434724091521\n",
      " sensitivity 0.8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = test.predict(val_X)\n",
    "threshold = 0.4\n",
    "probas = test.predict_proba(val_X)[:,1]\n",
    "preds = (probas >= threshold).astype('int')\n",
    "\n",
    "\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(y_pred = preds,y_true = val_y)\n",
    "precision = sklearn.metrics.precision_score(y_pred = preds,y_true = val_y)\n",
    "recall = sklearn.metrics.recall_score(y_pred = preds,y_true = val_y)\n",
    "roc_auc = sklearn.metrics.roc_auc_score(y_score = preds, y_true = val_y)\n",
    "print( \"{}\\nacc {}\\n precision {} \\n recall {} \\n rocauc {}\\n\".format(str(val.__class__.__name__)+\" \"+names[idx],\n",
    " accuracy, precision, recall, roc_auc))\n",
    "tn, fp, fn, tp  = sklearn.metrics.confusion_matrix(y_true=val_y, y_pred=preds).ravel()\n",
    "spec = tn/(tn+fp)\n",
    "sens = tp/(tp+fn)\n",
    "#         print(\"tn {}, fp {}, fn {}, tp {} \".format(tn, fp, fn, tp))\n",
    "print(\"specificity {}\\n sensitivity {}\\n\\n\".format(spec, sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://medium.com/@kunanba/what-is-roc-auc-and-how-to-visualize-it-in-python-f35708206663\n",
    "# only select [:,1] == probabilities for the positive class ONLY\n",
    "def get_preds(threshold, probabilities):\n",
    "    return [1 if prob > threshold else 0 for prob in probabilities]\n",
    "\n",
    "\n",
    "roc_values = []\n",
    "specificities, sensitivities = [],[]\n",
    "\n",
    "for thresh in np.linspace(0, 1, 100):\n",
    "    preds = get_preds(thresh, probas)\n",
    "    tn, fp, fn, tp = np.ravel(metrics.confusion_matrix(y_true=val_y, y_pred=preds))\n",
    "    tpr = tp/(tp+fn) #recall/sensitivity\n",
    "    fpr = fp/(fp+tn)\n",
    "    specificity = tn/(tn+fp) *100\n",
    "    sensitivity = tp/(tp+fn) *100\n",
    "     \n",
    "    roc_values.append([tpr, fpr])\n",
    "    specificities.append(specificity)\n",
    "    sensitivities.append(sensitivity)\n",
    "\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "ax.grid(True)\n",
    "\n",
    "sns.lineplot(x=np.linspace(0, 1, 100),y=specificities, label=\"specificity\", ax = ax)\n",
    "sns.lineplot(x=np.linspace(0, 1, 100),y=sensitivities, label =\"sensitivity\", ax = ax)\n",
    "\n",
    "ax.set_xlabel(\"thresholds\")\n",
    "ax.set_ylabel(\"percentage\")\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.1))\n",
    "ax.set_title(\"Specificity and Sensitivity\")\n",
    "fig.savefig(\"spec_sens\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5162907268170426"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should also check "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
